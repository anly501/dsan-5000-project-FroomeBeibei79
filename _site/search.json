[
  {
    "objectID": "Data.html",
    "href": "Data.html",
    "title": "Data Section",
    "section": "",
    "text": "This is a link to data in GitHub Click here"
  },
  {
    "objectID": "Data.html#driver-side",
    "href": "Data.html#driver-side",
    "title": "Data Section",
    "section": "Driver Side",
    "text": "Driver Side\n\nGender\nGender is a significant factor that has an impact on driver behavior. When it comes to fatal injury odds in passenger vehicle accidents, “the fatal injury odds for females were lower than males.” (p21)\n\n\nYoung driver\nAnother publication focus on young driver affect driver behavior analysis, as statistics state that “The rate of drivers involved in fatal traffic crashes per 100,000 licensed drivers for young female drivers was 25.51 in 2021. For young male drivers in 2021 the involvement rate was 60.28, more than twice that of young female drivers.” (U.S. Department of Transportation, National Highway Traffic Safety Administration. (2022). Traffic Safety Facts 2021 Data (Report No. 813492))"
  },
  {
    "objectID": "Data.html#vehicle-side",
    "href": "Data.html#vehicle-side",
    "title": "Data Section",
    "section": "Vehicle Side",
    "text": "Vehicle Side\n\nAcceleration\nThis one can be measureed in either G Force detector or the usage of throttle pedal\n\n\nBraking\nThis one can be measureed in either G Force detector or the usage of break pedal\n\n\nSpeed\nThis one can be measured with speedometer\n\n\nCornering\nThis one can be measured with G Force detector\n\n\nPhone Usage\nThis one can be used of a specfic device connected to the phone via bluetooth"
  },
  {
    "objectID": "Introduction.html",
    "href": "Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Written by Xingrui Huo Froome\nGU ID: xh231\n\n\nAs I moved to a new place for grad school, my car moved with me and so does the car insurance. However, as I requested for the new quote, I found out that the price went higher than expected. So I changed my insurance company and during the conversation with the new insurance company. I found out that there is one discount that can be added to my policy if I agree to let the insurance company to send me a device and put it in my vehicle to record my daily drive data.\nI found that very interesting because the insurance staff told me that as I driving, the device will record data and send it back to the insurance company. As to every end of policy, I will receive discount based on my driving records.\nI start to become interested about this little device. How does it record the data? What kind of data does it record? What kind of result can it get based on the data it records? I feel like that I can do the same thing, collect the same data, and do some similar analysis on myself. So I can do driver behavior analysis on myself. Of course, the most important thing in here is, how to do driver behavior analysis?\nBelow are two academic sources and some questions to start with:\n\n\n\n(Kaplan et al. 2015)\nThis is a link to source\n\n\nDriver drowsiness and distraction are two main reasons for traffic accidents and the related financial losses. Therefore, researchers have been working for more than a decade on designing driver inattention monitoring systems. As a result, several detection techniques for the detection of both drowsiness and distraction have been proposed in the literature. Some of these techniques were successfully adopted and implemented by the leading car companies. This paper discusses and provides a comprehensive insight into the well-established techniques for driver inattention monitoring and introduces the use of most recent and futuristic solutions exploiting mobile technologies such as smartphones and wearable devices. Then, a proposal is made for the active of such systems into car-to-car communication to support vehicular ad hoc network’s (VANET’s) primary aim of safe driving. We call this approach the dissemination of driver behavior via C2C communication. Throughout this paper, the most remarkable studies of the last five years were examined thoroughly in order to reveal the recent driver monitoring techniques and demonstrate the basic pros and cons. In addition, the studies were categorized into two groups: driver drowsiness and distraction. Then, research on the driver drowsiness was further divided into two main subgroups based on the exploitation of either visual features or nonvisual features. A comprehensive compilation, including used features, classification methods, accuracy rates, system parameters, and environmental details, was represented as tables to highlight the (dis)advantages and/or limitations of the aforementioned categories. A similar approach was also taken for the methods used for the detection of driver distraction.\n\n\n\nthe literature review highlighted the need for combining techniques, the importance of alerting mechanisms, and the potential of C2C communication for improving driver safety. Despite limitations, ongoing advancements indicate a promising future for driver monitoring and assistance systems.\n\n\n\n\n(Chan et al. 2019)\nThis is a link to source\n\n\nHuman factors are the primary catalyst for traffic accidents. Among different factors, fatigue, distraction, drunkenness, and/or recklessness are the most common types of abnormal driving behavior that leads to an accident. With technological advances, modern smartphones have the capabilities for driving behavior analysis. There has not yet been a comprehensive review on methodologies utilizing only a smartphone for drowsiness detection and abnormal driver behavior detection. In this paper, different methodologies proposed by different authors are discussed. It includes the sensing schemes, detection algorithms, and their corresponding accuracy and limitations. Challenges and possible solutions such as integration of the smartphone behavior classification system with the concept of context-aware, mobile crowdsensing, and active steering control are analyzed. The issue of model training and updating on the smartphone and cloud environment is also included.\n\n\n\nThe paper discusses the use of smartphone data as a valuable resource for analyzing driver behavior. It reviews various methodologies proposed by different authors for detecting abnormal driving patterns. While smartphone-based systems offer advantages over telematics boxes, there are significant challenges to consider for accurate driver behavior classification.\nKey challenges include the impact of varying light conditions on vision-based methodologies and the need to eliminate noise and external factors in sensor-based approaches, such as road conditions and vehicle components. Future research should address these issues. Additionally, eliminating the requirement for mounting the smartphone in a fixed position would enhance flexibility and convenience for drivers.\nThe paper also explores potential solutions, such as integrating smartphone-based driver behavior analysis with context-awareness, crowdsensing, and steering control, as well as mobile or cloud-based algorithm training and updates. While these solutions may not be perfect, they have the potential to address some of the challenges, suggesting that there is room for further improvement in smartphone-based behavior analysis systems.\n\n\n\n\n\n\n\nHow can we accurately measure and quantify aggressive driving behavior using telematics data?\nWhat are the most effective strategies for detecting and reducing instances of distracted driving?\nCan machine learning algorithms predict the likelihood of a driver engaging in risky behaviors based on historical data?\nHow does driver behavior vary across different age groups, genders, and experience levels, and what implications does this have for road safety?\nHow can data analytics be used to design targeted driver training programs that address specific behavioral issues?\n\n\n\n\n\nHow do external factors like road conditions and traffic congestion influence driver behavior, and how can this information be used to improve road safety?\nHow do weather conditions, such as rain, snow, and fog, affect road safety, and what strategies can be employed to mitigate their impact?\nHow can data science be used to analyze the effectiveness of road safety policies, such as seat belt laws and speed limits, in reducing accidents?\nWhat role does human psychology play in road safety, and how can behavioral insights be used to design safer road systems?\n\n\n\n\n\nHow does driver behavior impact fuel efficiency, and how can eco-driving habits be promoted to reduce emissions and fuel consumption?\nHow can driver behavior analysis be used to optimize traffic flow and reduce congestion in urban areas?\nHow can driver behavior data be anonymized and protected to ensure privacy while still extracting valuable insights for road safety?"
  },
  {
    "objectID": "Introduction.html#research-background",
    "href": "Introduction.html#research-background",
    "title": "Introduction",
    "section": "",
    "text": "As I moved to a new place for grad school, my car moved with me and so does the car insurance. However, as I requested for the new quote, I found out that the price went higher than expected. So I changed my insurance company and during the conversation with the new insurance company. I found out that there is one discount that can be added to my policy if I agree to let the insurance company to send me a device and put it in my vehicle to record my daily drive data.\nI found that very interesting because the insurance staff told me that as I driving, the device will record data and send it back to the insurance company. As to every end of policy, I will receive discount based on my driving records.\nI start to become interested about this little device. How does it record the data? What kind of data does it record? What kind of result can it get based on the data it records? I feel like that I can do the same thing, collect the same data, and do some similar analysis on myself. So I can do driver behavior analysis on myself. Of course, the most important thing in here is, how to do driver behavior analysis?\nBelow are two academic sources and some questions to start with:"
  },
  {
    "objectID": "Introduction.html#driver-behavior-analysis-for-safe-driving-a-survey",
    "href": "Introduction.html#driver-behavior-analysis-for-safe-driving-a-survey",
    "title": "Introduction",
    "section": "",
    "text": "(Kaplan et al. 2015)\nThis is a link to source\n\n\nDriver drowsiness and distraction are two main reasons for traffic accidents and the related financial losses. Therefore, researchers have been working for more than a decade on designing driver inattention monitoring systems. As a result, several detection techniques for the detection of both drowsiness and distraction have been proposed in the literature. Some of these techniques were successfully adopted and implemented by the leading car companies. This paper discusses and provides a comprehensive insight into the well-established techniques for driver inattention monitoring and introduces the use of most recent and futuristic solutions exploiting mobile technologies such as smartphones and wearable devices. Then, a proposal is made for the active of such systems into car-to-car communication to support vehicular ad hoc network’s (VANET’s) primary aim of safe driving. We call this approach the dissemination of driver behavior via C2C communication. Throughout this paper, the most remarkable studies of the last five years were examined thoroughly in order to reveal the recent driver monitoring techniques and demonstrate the basic pros and cons. In addition, the studies were categorized into two groups: driver drowsiness and distraction. Then, research on the driver drowsiness was further divided into two main subgroups based on the exploitation of either visual features or nonvisual features. A comprehensive compilation, including used features, classification methods, accuracy rates, system parameters, and environmental details, was represented as tables to highlight the (dis)advantages and/or limitations of the aforementioned categories. A similar approach was also taken for the methods used for the detection of driver distraction.\n\n\n\nthe literature review highlighted the need for combining techniques, the importance of alerting mechanisms, and the potential of C2C communication for improving driver safety. Despite limitations, ongoing advancements indicate a promising future for driver monitoring and assistance systems."
  },
  {
    "objectID": "Introduction.html#a-comprehensive-review-of-driver-behavior-analysis-utilizing-smartphones",
    "href": "Introduction.html#a-comprehensive-review-of-driver-behavior-analysis-utilizing-smartphones",
    "title": "Introduction",
    "section": "",
    "text": "(Chan et al. 2019)\nThis is a link to source\n\n\nHuman factors are the primary catalyst for traffic accidents. Among different factors, fatigue, distraction, drunkenness, and/or recklessness are the most common types of abnormal driving behavior that leads to an accident. With technological advances, modern smartphones have the capabilities for driving behavior analysis. There has not yet been a comprehensive review on methodologies utilizing only a smartphone for drowsiness detection and abnormal driver behavior detection. In this paper, different methodologies proposed by different authors are discussed. It includes the sensing schemes, detection algorithms, and their corresponding accuracy and limitations. Challenges and possible solutions such as integration of the smartphone behavior classification system with the concept of context-aware, mobile crowdsensing, and active steering control are analyzed. The issue of model training and updating on the smartphone and cloud environment is also included.\n\n\n\nThe paper discusses the use of smartphone data as a valuable resource for analyzing driver behavior. It reviews various methodologies proposed by different authors for detecting abnormal driving patterns. While smartphone-based systems offer advantages over telematics boxes, there are significant challenges to consider for accurate driver behavior classification.\nKey challenges include the impact of varying light conditions on vision-based methodologies and the need to eliminate noise and external factors in sensor-based approaches, such as road conditions and vehicle components. Future research should address these issues. Additionally, eliminating the requirement for mounting the smartphone in a fixed position would enhance flexibility and convenience for drivers.\nThe paper also explores potential solutions, such as integrating smartphone-based driver behavior analysis with context-awareness, crowdsensing, and steering control, as well as mobile or cloud-based algorithm training and updates. While these solutions may not be perfect, they have the potential to address some of the challenges, suggesting that there is room for further improvement in smartphone-based behavior analysis systems."
  },
  {
    "objectID": "Introduction.html#questions",
    "href": "Introduction.html#questions",
    "title": "Introduction",
    "section": "",
    "text": "How can we accurately measure and quantify aggressive driving behavior using telematics data?\nWhat are the most effective strategies for detecting and reducing instances of distracted driving?\nCan machine learning algorithms predict the likelihood of a driver engaging in risky behaviors based on historical data?\nHow does driver behavior vary across different age groups, genders, and experience levels, and what implications does this have for road safety?\nHow can data analytics be used to design targeted driver training programs that address specific behavioral issues?\n\n\n\n\n\nHow do external factors like road conditions and traffic congestion influence driver behavior, and how can this information be used to improve road safety?\nHow do weather conditions, such as rain, snow, and fog, affect road safety, and what strategies can be employed to mitigate their impact?\nHow can data science be used to analyze the effectiveness of road safety policies, such as seat belt laws and speed limits, in reducing accidents?\nWhat role does human psychology play in road safety, and how can behavioral insights be used to design safer road systems?\n\n\n\n\n\nHow does driver behavior impact fuel efficiency, and how can eco-driving habits be promoted to reduce emissions and fuel consumption?\nHow can driver behavior analysis be used to optimize traffic flow and reduce congestion in urban areas?\nHow can driver behavior data be anonymized and protected to ensure privacy while still extracting valuable insights for road safety?"
  },
  {
    "objectID": "slides/slides.html#germany-vehicles",
    "href": "slides/slides.html#germany-vehicles",
    "title": "Intro to Cars",
    "section": "Germany Vehicles",
    "text": "Germany Vehicles\n\nAudi\nBMW\nMercedes-Benz\nPorsche"
  },
  {
    "objectID": "slides/slides.html#america-vehicles",
    "href": "slides/slides.html#america-vehicles",
    "title": "Intro to Cars",
    "section": "America Vehicles",
    "text": "America Vehicles\n\nFord\nLincoln\nJeep\nCorvette\nDodge"
  },
  {
    "objectID": "slides/slides.html#asia-vehicles",
    "href": "slides/slides.html#asia-vehicles",
    "title": "Intro to Cars",
    "section": "Asia Vehicles",
    "text": "Asia Vehicles\n\nHonda\nToyota\nXpeng\nNIO"
  },
  {
    "objectID": "slides/slides.html#europe-cars---audi-a-series",
    "href": "slides/slides.html#europe-cars---audi-a-series",
    "title": "Intro to Cars",
    "section": "Europe Cars - Audi A Series",
    "text": "Europe Cars - Audi A Series\n\n\nA1\nA3\nA4\nA5\nA6\nA7\nA8"
  },
  {
    "objectID": "slides/slides.html#audi-a4",
    "href": "slides/slides.html#audi-a4",
    "title": "Intro to Cars",
    "section": "Audi A4",
    "text": "Audi A4\n\nAudi A4"
  },
  {
    "objectID": "slides/slides.html#audi-a8",
    "href": "slides/slides.html#audi-a8",
    "title": "Intro to Cars",
    "section": "AUdi A8",
    "text": "AUdi A8\n\nAudi A8"
  },
  {
    "objectID": "slides/slides.html#a-citation",
    "href": "slides/slides.html#a-citation",
    "title": "Intro to Cars",
    "section": "A Citation",
    "text": "A Citation\nThis approach enables you to use the same bibliography with different citation styles without having to change anything about your document or the bibliography itself apart from the bibliography style when your paper is finally compiled for print. (Fenn 2006)"
  },
  {
    "objectID": "slides/slides.html#a-plot",
    "href": "slides/slides.html#a-plot",
    "title": "Intro to Cars",
    "section": "A Plot",
    "text": "A Plot\n\n\n\n\n\n\n\nFenn, Jürgen. 2006. “Managing Citations and Your Bibliography with BibTEX.” The PracTEX Journal. http://svn.tug.org/pracjourn/2006-4/fenn/fenn.pdf."
  },
  {
    "objectID": "Code.html",
    "href": "Code.html",
    "title": "Code Section",
    "section": "",
    "text": "Link to my GitHubMy GitHub\nThis is a link to formula 1 Formula 1"
  },
  {
    "objectID": "Code.html#first-is-links-section",
    "href": "Code.html#first-is-links-section",
    "title": "Code Section",
    "section": "",
    "text": "Link to my GitHubMy GitHub\nThis is a link to formula 1 Formula 1"
  },
  {
    "objectID": "Data Cleaning Python.html",
    "href": "Data Cleaning Python.html",
    "title": "Drop the specified columns by index",
    "section": "",
    "text": "First I use NewsAPI to get text data from NewsAPI on different key words in terms of driver behavior analysis\nThe key words I used are: driving behavior, distracted driving, driver risk assessment, driver profilling\nimport requests\nimport json\nimport re\nimport os\nimport pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nbaseURL = \"https://newsapi.org/v2/everything?\"\ntotal_requests=1\nverbose=True\n\nAPI_KEY='2133663c4ec54af8a9839f0c500203de'\nTOPIC1 = 'driver profiling'\n\nURLpost1 = {'apiKey': API_KEY,\n            'q': '+'+TOPIC1,\n            'sortBy': 'relevancy',\n            'totalRequests': 1}\n\nprint(baseURL)\n\nresponse1 = requests.get(baseURL, URLpost1) \n\nresponse1 = response1.json() \n\nprint(json.dumps(response1, indent=2))\n\nfrom datetime import datetime\ntimestamp = datetime.now().strftime(\"%Y-%m-%d-H%H-M%M-S%S\")\n\noutput_file_path = os.path.join(\"data\", f'{timestamp}-topic1-newapi-raw-data-driver-profilling.json')\n\nwith open(output_file_path, 'w') as outfile:\n    json.dump(response1, outfile, indent=4)\n\n\nHere we have extracted the readings from News API, what I will do next is to filter the title, publisher, etc\n\n\nNext is how I scrape data from pdf file\n\nimport csv\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\naccident = pd.read_csv('Data/FARS2021NationalCSV/accident.csv', encoding='ISO-8859-1')\nevent = pd.read_csv('Data/FARS2021NationalCSV/cevent.csv', encoding='ISO-8859-1')\naccident.columns = accident.columns.str.strip()\nevent.columns = event.columns.str.strip()\n\naccident_columns_to_drop = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n                   36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n                   64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n\naccident = accident.drop(accident.columns[accident_columns_to_drop], axis=1)\n\nevent_columns_to_drop = [9, 10, 11, 12]\nevent = event.drop(event.columns[event_columns_to_drop], axis = 1)\n\ndf = pd.merge(accident, event, on='ST_CASE', how='inner')\ndf = df.drop(columns=['STATE_y', 'STATENAME_y'])\n\n\nnumerical_vars = df.select_dtypes(include=[np.number])\nnumerical_summary = numerical_vars.describe()\n\n# Calculate variance for numerical variables (since it's not included in the describe method by default)\nvariance = numerical_vars.var()\n\n# Add variance to the summary statistics\nnumerical_summary.loc['variance'] = variance\n\nnumerical_summary\n\nsns.set_style(\"whitegrid\")\n\n# Function to create bar plots for categorical variables\ndef plot_categorical_distribution(data, column_name, plot_size=(10, 6), rotation_angle=90):\n    plt.figure(figsize=plot_size)\n    ax = sns.countplot(data=data, y=column_name, order=data[column_name].value_counts().index,  palette=\"husl\")\n    ax.set_title(f'Crash Distribution Summary of {column_name}', fontsize=15)\n    ax.set_ylabel(column_name, fontsize=12)\n    ax.set_xlabel('Count', fontsize=12)\n    plt.xticks(rotation=rotation_angle)\n    plt.show()\n\n# Plot the distribution of STATENAME_x\nplot_categorical_distribution(df, 'STATENAME_x')\n\nplot_categorical_distribution(df, 'DAY_WEEKNAME', rotation_angle=0)\n\n\nplot_categorical_distribution(df, 'AOI1NAME', plot_size=(10, 8))\n\n\n# Calculate the correlation matrix for the numerical variables Step 4\ncorrelation_matrix = numerical_vars.corr()\n\ncorrelation_matrix\n\n# Set the size of the plot\nplt.figure(figsize=(10, 8))\n\n# Create a heatmap to visualize the correlation matrix\nax = sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n\n# Set the title and show the plot\nax.set_title('Correlation Matrix', fontsize=15)\nplt.show()\n\n\n# Convert HOUR from numeric to categorical to better handle the 99 (unknown) values\ndf['HOUR'] = df['HOUR'].astype(str).replace('99', 'Unknown')\n\n# Create a pivot table to count the number of entries for each combination of DAY_WEEKNAME and HOUR\nhour_weekday_pivot = pd.pivot_table(df, index='DAY_WEEKNAME', columns='HOUR', aggfunc='size', fill_value=0)\n\n# Order the days of the week\ndays_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\nhour_weekday_pivot = hour_weekday_pivot.reindex(days_order)\n\n# Create the heatmap\nplt.figure(figsize=(15, 7))\nax = sns.heatmap(hour_weekday_pivot, cmap=\"YlGnBu\", linewidths=.5)\n\n# Set the title and labels\nax.set_title('Number of Entries by Day of the Week and Hour of the Day', fontsize=15)\nax.set_xlabel('Hour of the Day', fontsize=12)\nax.set_ylabel('Day of the Week', fontsize=12)\n\nplt.show()\n\n# Group the data by state and calculate the total number of entries for each state\nstate_group = df.groupby('STATENAME_x').size().sort_values(ascending=False)\n\nstate_group\n\n# Set the size of the plot\nplt.figure(figsize=(12, 8))\n\n# Create a bar plot for the number of entries by state\nax = sns.barplot(x=state_group.index, y=state_group.values, palette=\"husl\")\n\n# Set the title and labels\nax.set_title('Number of Entries by State', fontsize=15)\nax.set_xlabel('State', fontsize=12)\nax.set_ylabel('Number of Entries', fontsize=12)\nplt.xticks(rotation=90)\n\n# Show the plot\nplt.show()\n\n# Convert HOUR back to numeric, treating \"Unknown\" as a missing value\ndf['HOUR'] = pd.to_numeric(df['HOUR'], errors='coerce')\n\n# Define a function to categorize the time of day\ndef categorize_time_of_day(hour):\n    if pd.isna(hour):\n        return \"Unknown\"\n    elif 6 &lt;= hour &lt; 12:\n        return \"Morning\"\n    elif 12 &lt;= hour &lt; 18:\n        return \"Afternoon\"\n    elif 18 &lt;= hour &lt; 24:\n        return \"Evening\"\n    else:\n        return \"Night\"\n\n# Apply the function to create a new variable \"TIME_OF_DAY\"\ndf['TIME_OF_DAY'] = df['HOUR'].apply(categorize_time_of_day)\n\n# Group the data by \"TIME_OF_DAY\" and calculate the total number of entries for each time segment\ntime_of_day_group = df.groupby('TIME_OF_DAY').size().sort_index()\n\ntime_of_day_group\n\n# Set the size of the plot\nplt.figure(figsize=(10, 6))\n\n# Create a bar plot for the number of entries by time of day\nax = sns.barplot(x=time_of_day_group.index, y=time_of_day_group.values, palette=\"husl\")\n\n# Set the title and labels\nax.set_title('Number of Entries by Time of Day', fontsize=15)\nax.set_xlabel('Time of Day', fontsize=12)\nax.set_ylabel('Number of Entries', fontsize=12)\n\n# Show the plot\nplt.show()\n\n\n\n# Set the size of the plots\nplt.figure(figsize=(15, 10))\n\n# Create box plots for the numerical variables\nfor i, column in enumerate(numerical_vars.columns, 1):\n    plt.subplot(3, 3, i)\n    sns.boxplot(x=df[column])\n    plt.title(column)\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "Data Gathering.html",
    "href": "Data Gathering.html",
    "title": "Data Gathering",
    "section": "",
    "text": "The recod data I collected are mainly from NHTSA, the National Highway Traffic Safety Administration. The NHTSA have publications that contains many data that is quite useful for this research. However, some data are available in differnt kinds besides csv. So it will take quite a time to clean\n\n\nNow the raw data looks like this,  It’s quite messy on the top. So, I will need to clean the column names to make it tidy.\nAfter cleaning process, the data now looks like this, \nNote this is not enough, I still need to further tidy the column names to make it better\n\n\n\nThe data available about young driver information is mainly from NHTSA, and it’s in PDF format, so I will need to first download the data, scrape them into csv file, and then do more analysis.\n\n\n\n\nThere are also some text data available that I use API to pull them from the webiste. I will further clean them and also put them onto the page. \nSo right now I will need to sort the text out, like find out the publisher of the paper, the title, the description, etc."
  },
  {
    "objectID": "Data Gathering.html#record-data",
    "href": "Data Gathering.html#record-data",
    "title": "Data Gathering",
    "section": "",
    "text": "The recod data I collected are mainly from NHTSA, the National Highway Traffic Safety Administration. The NHTSA have publications that contains many data that is quite useful for this research. However, some data are available in differnt kinds besides csv. So it will take quite a time to clean\n\n\nNow the raw data looks like this,  It’s quite messy on the top. So, I will need to clean the column names to make it tidy.\nAfter cleaning process, the data now looks like this, \nNote this is not enough, I still need to further tidy the column names to make it better\n\n\n\nThe data available about young driver information is mainly from NHTSA, and it’s in PDF format, so I will need to first download the data, scrape them into csv file, and then do more analysis."
  },
  {
    "objectID": "Data Gathering.html#text-data",
    "href": "Data Gathering.html#text-data",
    "title": "Data Gathering",
    "section": "",
    "text": "There are also some text data available that I use API to pull them from the webiste. I will further clean them and also put them onto the page. \nSo right now I will need to sort the text out, like find out the publisher of the paper, the title, the description, etc."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "Hi! My name is Xingrui Huo, with GU net ID: xh231\nThis is a webpage that introduces me.\n\n\n\n\nGeorgetown University, Master of Science, Data Science & Analytics\nGeoorgwetown is an excellent unviersity that sits in Georgetown, Washington, D.C.\n\n\n\nI spent my undergraduate life at Rutgers, the State University of New Jersey. RU Rah Rah!\n\n\n\nBefore my undergrad, I stayed back in China for 18 years, born and raised up in the same place."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "About Me",
    "section": "",
    "text": "Georgetown University, Master of Science, Data Science & Analytics\nGeoorgwetown is an excellent unviersity that sits in Georgetown, Washington, D.C.\n\n\n\nI spent my undergraduate life at Rutgers, the State University of New Jersey. RU Rah Rah!\n\n\n\nBefore my undergrad, I stayed back in China for 18 years, born and raised up in the same place."
  },
  {
    "objectID": "index.html#sports",
    "href": "index.html#sports",
    "title": "About Me",
    "section": "Sports",
    "text": "Sports\nI love to bike, and watch Formula 1 during the weekend. Sometimes I also play the simulator on PC just to have fun, and experience the Formula 1 in a more intuitive way"
  },
  {
    "objectID": "index.html#things-in-life",
    "href": "index.html#things-in-life",
    "title": "About Me",
    "section": "Things in Life",
    "text": "Things in Life\nI like cars, A LOT. I love everything from the design of the car, the engine, transmission of the car, to the difference on configration of the car due to the different law and environmental requirments in different countries. I also have a very strong interest on analyzing anything data-related to the car. I have done a project before, which focuses on analyzing lap time driven by myself in game F1 22. Now I have switched tracks to collect data from real-world, and to see if the data can inspire me in some ways!"
  },
  {
    "objectID": "index.html#foods",
    "href": "index.html#foods",
    "title": "About Me",
    "section": "Foods!",
    "text": "Foods!\nI love trying new foods in every places around the world. I also very much engaged with trying to re-make the same food at home. Ramen, steak, burrito, everything! Below are something I have tried to cook at home, and it was very good at the end!\n\n\n\nRamen\nDumpling\nZongzi\n\n\n\nPizza\nBarbecue\nSteak"
  },
  {
    "objectID": "index.html#this-is-a-hilarious-quote-from-jeremy-clarkson",
    "href": "index.html#this-is-a-hilarious-quote-from-jeremy-clarkson",
    "title": "About Me",
    "section": "This is a hilarious quote from Jeremy Clarkson",
    "text": "This is a hilarious quote from Jeremy Clarkson\n\nSpeed has never killed anyone, suddenly becoming stationary… That’s what gets you – Jeremy Clarkson\n\n\nSome Requirements\nThis is an inline math equation:  \\(x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\\).\nThe area of a circle with radius (r) is given by the formula:\n\\[\n[A = \\pi r^2]\n\\]\nWhere:\n\n(A) is the area of the circle.\n(pi) is approximately 3.14159.\n(r) is the radius of the circle.\n\n\n\n\n\ngraph LR;\n  A[A4, A5] --&gt; B(S4, S5);\n  B --&gt; C(RS4, RS5);\n\n\n\n\n\n\nThis approach enables you to use the same bibliography with different citation styles without having to change anything about your document or the bibliography itself apart from the bibliography style when your paper is finally compiled for print. [@fenn_managing_2006]"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "About Me",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOne same engine have slightly different models based on differnt vehicles, country law’s requirments, and marketing needs↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "about.html#it-will-show-some-detailed-information-regrading-different-manufactures",
    "href": "about.html#it-will-show-some-detailed-information-regrading-different-manufactures",
    "title": "About",
    "section": "it will show some detailed information regrading different manufactures",
    "text": "it will show some detailed information regrading different manufactures\n\nMore will coming soon…\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Generate some sample data\nx = np.linspace(0, 2 * np.pi, 100)  # Create an array of values from 0 to 2*pi\ny = np.sin(x)  # Compute the sine of each value\n\n# Create a plot\nplt.figure(figsize=(8, 4))  # Set the figure size\nplt.plot(x, y, label='sin(x)', color='blue', linestyle='-', linewidth=2)  # Create the plot\n\n# Add labels and a legend\nplt.xlabel('x')  # X-axis label\nplt.ylabel('y')  # Y-axis label\nplt.title('Sine Function')  # Title of the plot\nplt.legend()\n\n# Show the plot\nplt.grid(True)  # Add grid lines\nplt.show()"
  },
  {
    "objectID": "Data Cleaning R.html",
    "href": "Data Cleaning R.html",
    "title": "Xingrui's Project",
    "section": "",
    "text": "Below is the code to clean the gender dataset\n\nlibrary(readxl)\nlibrary(tidyverse)\ngender &lt;- read_excel(\"data/dl220.xls\")\ngender &lt;- gender[-(1:2),]\ncolnames(gender) &lt;- gender[1,]\ngender &lt;- gender[-1,]\ngender &lt;- gender[1:(nrow(gender) -4),]\ncolnames(gender)[1] &lt;- \"Year\"\ngender &lt;- gender[-1,]\ncolnames1 &lt;- paste0(colnames(gender), unlist(gender[1,]))\ncolnames(gender) &lt;- colnames1\ngender &lt;- gender[-1,]\n\nnames &lt;- which(duplicated(colnames(gender)))\nfor (col_index in names){\n  colnames(gender)[col_index] &lt;- paste0(colnames(gender)[col_index], \"_\", col_index)\n}"
  },
  {
    "objectID": "Data Cleaning.html",
    "href": "Data Cleaning.html",
    "title": "Data Cleaning Code",
    "section": "",
    "text": "This is code section\n\nR Data\nThis will be a link to another page where you can see the code of how to clean the dataset in R\n\n\nPython Data\nThis will be a link to another page where you can see the code of how to clean the dataset in python"
  },
  {
    "objectID": "Data Exploration.html",
    "href": "Data Exploration.html",
    "title": "Explore the Data",
    "section": "",
    "text": "In this page we will explore the data in various kinds of ways to see what might catch out eyes\n\n\nThe data I have here is the accident summary conducted by the Fatality Analysis Reporting System (FARS); FARS is a nationwide census providing NHTSA, Congress and the American public yearly data regarding fatal injuries suffered in motor vehicle traffic crashes. This data contains very detailed information that records the condition of each accident.\nThe data was separated into different files, which can be joined together by a universal column, case number. So we can combine different files to get different information. \n\n\n\nSome basic summary statistics are mean, standard deviation, minimum, median, and variance. Among all these descriptive statistics, the only meaningful column is time, specifically, hour. That is when the accident happened during the day. \n\n\n\nThere are a couple of visulaized plots help us to see intuitivalely\n\n\nBelow the plot provides an overview of accident summaries distributed by state, allowing us to identify the states with the highest and lowest accident counts. \nFrom the chart, we can observe that the distribution is not uniform across states. Some states have a significantly higher number of entries compared to others. This could be due to various factors such as population, geographical size, traffic volume, or data collection methods.\n\n\n\nThis plot reveals the days of the week that are most likely to experience fatal crashes \nThe distribution of entries is relatively uniform across the days of the week. There seems to be a slight increase in entries on Saturdays and Sundays. This could suggest a potential increase in incidents or events during the weekends, but further analysis would be needed to confirm any such trends and to understand their causes.\n\n\n\nThis plot illustrates the direction in which a vehicle is most likely to experience an accident \nFrom this chart, we can observe that: “Non-Harmful Event” and “12 Clock Point” are the most common areas of impact recorded in the dataset. There are various other areas of impact with fewer occurrences. This information could be useful for understanding the common types of impacts and their frequencies, which might help in identifying areas for safety improvements.\n\n\n\n\nIn the Correlation Analysis step, we will:\n\nCalculate the correlation matrix for the numerical variables in the dataset.\nVisualize the correlations using a heatmap.\n\n\n\nLet’s start by calculating the correlation matrix. \nAs we can see from the matrix, STATE_x and ST_CASE have a very high positive correlation (almost 1), which is expected as the case number (ST_CASE) is likely assigned sequentially within each state.\nHOUR and MINUTE have a positive correlation of 0.2644, indicating a moderate relationship.\nEVENTNUM and VNUMBER1 also have a strong positive correlation of 0.8227, suggesting a strong relationship between these two variables.\nAOI1 and SOE have a positive correlation of 0.5630, indicating a moderate to strong relationship.\n\n\n\nNext, we will visualize these correlations using a heatmap to make it easier to interpret the relationships between variables. \nThe heatmap above visualizes the correlation matrix, providing a color-coded representation of the correlation coefficients between each pair of numerical variables.\nFrom the heatmap, we can easily identify strong positive correlations (dark red areas) and observe the relationships between different variables. For example, the strong positive correlation between “EVENTNUM” and “VNUMBER1” is clearly visible.\n\n\n\nTo investigate the relationship between the day of the week and the hour of the day, we can create a heatmap that displays the count of entries for each combination of day and hour. This will help us visualize if there are certain times of the day that are more prone to incidents on specific weekdays \nFrom this visualization, we can observe that:\nThe hours with the most entries tend to be in the afternoon and evening, particularly from around 14:00 to 18:00. This could be due to increased traffic during these hours.\nThere are fewer entries during the early morning hours, which is expected since there is typically less traffic at that time.\nSaturday and Sunday show a slightly different pattern compared to the weekdays, with more entries occurring late at night and in the early morning hours. This could be indicative of different driving behaviors during the weekends, potentially related to social activities.\nThe column labeled “Unknown” represents entries where the hour was not recorded or was unknown. These entries are spread across all days of the week.\n\n\n\n\nBased on the exploratory data analysis we’ve conducted so far, here are some potential hypotheses and questions:\n\n\nHypothesis: There are more incidents in the afternoon and evening compared to other times of the day. Potential Analysis: Investigate if certain types of incidents are more likely to occur during these times.\n\n\n\nHypothesis: Driving behavior during the weekends, especially late at night and in the early morning hours, leads to more incidents.\nPotential Analysis: Examine the types of incidents that occur during these times and if they are different from weekday incidents.\n\n\n\nQuestion: Why do some states have significantly more incidents recorded in the dataset? Is it due to population, traffic volume, or data collection methods?\nPotential Analysis: Normalize the data by population or traffic volume to better understand the state-wise distribution.\n\n\n\nHypothesis: Certain areas of impact, such as the “Non-Harmful Event” and “12 Clock Point”, are more common.\nPotential Analysis: Investigate the circumstances that lead to these common impact areas.\n\n\n\nHypothesis: The “Motor Vehicle In-Transport” event is the most common sequence of events leading to incidents.\nPotential Analysis: Explore what specific situations or factors contribute to this sequence of events.\n\n\n\n\nIf applicable, group or segment the data based on relevant criteria to uncover insights within specific subgroups.\n\n\n The data grouped by state shows the total number of entries (incidents) for each state:\n\nCalifornia and Texas have the highest number of entries, with 11,952 and 11,787 incidents respectively.\nStates like Alaska, District of Columbia, and Rhode Island have the lowest number of entries, all below 150 incidents.\nThis distribution could be influenced by various factors such as population, geographical size, traffic volume, and data collection methods.\n\n\n\n\n From this distribution, we can observe that:\n\nThe number of incidents is higher in the evening, followed by the afternoon and night.\nThe morning has the lowest number of incidents.\nThere are a significant number of incidents during the night, which could be worth investigating further, especially given the reduced traffic volumes during these hours.\n\n\n\n\n\nTo identify outliers, we can use various methods such as:\n\nZ-Scores: Calculate the Z-score of each data point and identify points with a Z-score beyond a certain threshold (e.g., |Z| &gt; 3).\nIQR Method: Calculate the Interquartile Range (IQR) and identify points beyond 1.5 * IQR from the quartiles.\nVisualizations: Use box plots to visually identify outliers.\n\nSince we have multiple numerical variables in our dataset, we will start by using box plots to visually identify outliers in these variables. \nFrom the box plots, we can observe that:\n\nSTATE_x: There are no visible outliers.\nST_CASE: This is a case number, and it doesn’t have outliers in the traditional sense\nDAY: There are no visible outliers.\nHOUR: There are values set to 99, which likely represent unknown or missing values rather than outliers.\nMINUTE: Similar to “HOUR”, there are values set to 99.\nEVENTNUM, VNUMBER1, AOI1, SOE: These variables have a significant number of high values that could be considered outliers. However, without more context on what these numbers represent, it’s challenging to definitively label them as outliers.\n\nTo properly handle the potential outliers, we would need additional context on the data and the variables, especially for the ones with coded values (EVENTNUM, VNUMBER1, AOI1, SOE).\n\n\n\n\n\nThe dataset contains information about various incidents, with a total of 112,725 entries. There are 13 columns, consisting of both numerical and categorical variables.\n\n\n\n\n\n\nSTATE_x: Represents the state codes, ranging from 1 to 56.\nST_CASE: A unique case number assigned to each incident.\nDAY: Day of the incident, ranging from 1 to 31.\nHOUR: Hour of the day when the incident occurred, ranging from 0 to 99 (with 99 representing unknown values).\nMINUTE: Minute of the hour when the incident occurred, ranging from 0 to 99 (with 99 representing unknown values).\nEVENTNUM, VNUMBER1, AOI1, SOE: Coded variables representing various aspects of the incidents.\n\n\n\n\n\nSTATENAME_x: The name of the state where the incident occurred.\nDAY_WEEKNAME: The day of the week when the incident occurred.\nAOI1NAME: Descriptions related to the area of impact.\nSOENAME: Descriptions related to the sequence of events.\n\n\n\n\n\n\n\n\nSTATENAME_x: California and Texas have the highest number of incidents.\nDAY_WEEKNAME: Incidents are fairly evenly distributed across days of the week, with a slight increase on Saturdays and Sundays.\nAOI1NAME: “Non-Harmful Event” and “12 Clock Point” are the most common areas of impact\nSOENAME: “Motor Vehicle In-Transport” is the most common sequence of events.\n\n\n\n\n\nA strong positive correlation exists between STATE_x and ST_CASE, as case numbers are likely assigned sequentially within each state. HOUR and MINUTE have a positive correlation, suggesting a moderate relationship. EVENTNUM and VNUMBER1 also show a strong positive correlation. AOI1 and SOE have a moderate to strong positive correlation.\n\n\n\nHypotheses were generated related to time of day and incidents, weekend driving behavior, state-wise distribution of incidents, impact areas, and sequence of events.\n\n\n\nBy State:\nCalifornia and Texas have the highest number of incidents. Alaska, District of Columbia, and Rhode Island have the lowest.\nBy Time of Day:\nThe evening has the highest number of incidents, followed by the afternoon and night. The morning has the lowest number of incidents.\n\n\n\nPotential outliers were identified in the variables HOUR, MINUTE, EVENTNUM, VNUMBER1, AOI1, and SOE. The values 99 in HOUR and MINUTE are likely placeholders for unknown values.\n\n\n\n\nThe analysis was performed using Python, leveraging libraries such as:\nPandas: For data manipulation and analysis. Matplotlib and Seaborn: For data visualization. NumPy: For numerical computations."
  },
  {
    "objectID": "Data Exploration.html#data-understanding",
    "href": "Data Exploration.html#data-understanding",
    "title": "Explore the Data",
    "section": "",
    "text": "The data I have here is the accident summary conducted by the Fatality Analysis Reporting System (FARS); FARS is a nationwide census providing NHTSA, Congress and the American public yearly data regarding fatal injuries suffered in motor vehicle traffic crashes. This data contains very detailed information that records the condition of each accident.\nThe data was separated into different files, which can be joined together by a universal column, case number. So we can combine different files to get different information."
  },
  {
    "objectID": "Data Exploration.html#descriptive-statistics",
    "href": "Data Exploration.html#descriptive-statistics",
    "title": "Explore the Data",
    "section": "",
    "text": "Some basic summary statistics are mean, standard deviation, minimum, median, and variance. Among all these descriptive statistics, the only meaningful column is time, specifically, hour. That is when the accident happened during the day."
  },
  {
    "objectID": "Data Exploration.html#data-visualization",
    "href": "Data Exploration.html#data-visualization",
    "title": "Explore the Data",
    "section": "",
    "text": "There are a couple of visulaized plots help us to see intuitivalely\n\n\nBelow the plot provides an overview of accident summaries distributed by state, allowing us to identify the states with the highest and lowest accident counts. \nFrom the chart, we can observe that the distribution is not uniform across states. Some states have a significantly higher number of entries compared to others. This could be due to various factors such as population, geographical size, traffic volume, or data collection methods.\n\n\n\nThis plot reveals the days of the week that are most likely to experience fatal crashes \nThe distribution of entries is relatively uniform across the days of the week. There seems to be a slight increase in entries on Saturdays and Sundays. This could suggest a potential increase in incidents or events during the weekends, but further analysis would be needed to confirm any such trends and to understand their causes.\n\n\n\nThis plot illustrates the direction in which a vehicle is most likely to experience an accident \nFrom this chart, we can observe that: “Non-Harmful Event” and “12 Clock Point” are the most common areas of impact recorded in the dataset. There are various other areas of impact with fewer occurrences. This information could be useful for understanding the common types of impacts and their frequencies, which might help in identifying areas for safety improvements."
  },
  {
    "objectID": "Data Exploration.html#correlation-analysis",
    "href": "Data Exploration.html#correlation-analysis",
    "title": "Explore the Data",
    "section": "",
    "text": "In the Correlation Analysis step, we will:\n\nCalculate the correlation matrix for the numerical variables in the dataset.\nVisualize the correlations using a heatmap.\n\n\n\nLet’s start by calculating the correlation matrix. \nAs we can see from the matrix, STATE_x and ST_CASE have a very high positive correlation (almost 1), which is expected as the case number (ST_CASE) is likely assigned sequentially within each state.\nHOUR and MINUTE have a positive correlation of 0.2644, indicating a moderate relationship.\nEVENTNUM and VNUMBER1 also have a strong positive correlation of 0.8227, suggesting a strong relationship between these two variables.\nAOI1 and SOE have a positive correlation of 0.5630, indicating a moderate to strong relationship.\n\n\n\nNext, we will visualize these correlations using a heatmap to make it easier to interpret the relationships between variables. \nThe heatmap above visualizes the correlation matrix, providing a color-coded representation of the correlation coefficients between each pair of numerical variables.\nFrom the heatmap, we can easily identify strong positive correlations (dark red areas) and observe the relationships between different variables. For example, the strong positive correlation between “EVENTNUM” and “VNUMBER1” is clearly visible.\n\n\n\nTo investigate the relationship between the day of the week and the hour of the day, we can create a heatmap that displays the count of entries for each combination of day and hour. This will help us visualize if there are certain times of the day that are more prone to incidents on specific weekdays \nFrom this visualization, we can observe that:\nThe hours with the most entries tend to be in the afternoon and evening, particularly from around 14:00 to 18:00. This could be due to increased traffic during these hours.\nThere are fewer entries during the early morning hours, which is expected since there is typically less traffic at that time.\nSaturday and Sunday show a slightly different pattern compared to the weekdays, with more entries occurring late at night and in the early morning hours. This could be indicative of different driving behaviors during the weekends, potentially related to social activities.\nThe column labeled “Unknown” represents entries where the hour was not recorded or was unknown. These entries are spread across all days of the week."
  },
  {
    "objectID": "Data Exploration.html#hypothesis-generation",
    "href": "Data Exploration.html#hypothesis-generation",
    "title": "Explore the Data",
    "section": "",
    "text": "Based on the exploratory data analysis we’ve conducted so far, here are some potential hypotheses and questions:\n\n\nHypothesis: There are more incidents in the afternoon and evening compared to other times of the day. Potential Analysis: Investigate if certain types of incidents are more likely to occur during these times.\n\n\n\nHypothesis: Driving behavior during the weekends, especially late at night and in the early morning hours, leads to more incidents.\nPotential Analysis: Examine the types of incidents that occur during these times and if they are different from weekday incidents.\n\n\n\nQuestion: Why do some states have significantly more incidents recorded in the dataset? Is it due to population, traffic volume, or data collection methods?\nPotential Analysis: Normalize the data by population or traffic volume to better understand the state-wise distribution.\n\n\n\nHypothesis: Certain areas of impact, such as the “Non-Harmful Event” and “12 Clock Point”, are more common.\nPotential Analysis: Investigate the circumstances that lead to these common impact areas.\n\n\n\nHypothesis: The “Motor Vehicle In-Transport” event is the most common sequence of events leading to incidents.\nPotential Analysis: Explore what specific situations or factors contribute to this sequence of events."
  },
  {
    "objectID": "Data Exploration.html#data-grouping-and-segmentation",
    "href": "Data Exploration.html#data-grouping-and-segmentation",
    "title": "Explore the Data",
    "section": "",
    "text": "If applicable, group or segment the data based on relevant criteria to uncover insights within specific subgroups.\n\n\n The data grouped by state shows the total number of entries (incidents) for each state:\n\nCalifornia and Texas have the highest number of entries, with 11,952 and 11,787 incidents respectively.\nStates like Alaska, District of Columbia, and Rhode Island have the lowest number of entries, all below 150 incidents.\nThis distribution could be influenced by various factors such as population, geographical size, traffic volume, and data collection methods.\n\n\n\n\n From this distribution, we can observe that:\n\nThe number of incidents is higher in the evening, followed by the afternoon and night.\nThe morning has the lowest number of incidents.\nThere are a significant number of incidents during the night, which could be worth investigating further, especially given the reduced traffic volumes during these hours."
  },
  {
    "objectID": "Data Exploration.html#identifying-outliers",
    "href": "Data Exploration.html#identifying-outliers",
    "title": "Explore the Data",
    "section": "",
    "text": "To identify outliers, we can use various methods such as:\n\nZ-Scores: Calculate the Z-score of each data point and identify points with a Z-score beyond a certain threshold (e.g., |Z| &gt; 3).\nIQR Method: Calculate the Interquartile Range (IQR) and identify points beyond 1.5 * IQR from the quartiles.\nVisualizations: Use box plots to visually identify outliers.\n\nSince we have multiple numerical variables in our dataset, we will start by using box plots to visually identify outliers in these variables. \nFrom the box plots, we can observe that:\n\nSTATE_x: There are no visible outliers.\nST_CASE: This is a case number, and it doesn’t have outliers in the traditional sense\nDAY: There are no visible outliers.\nHOUR: There are values set to 99, which likely represent unknown or missing values rather than outliers.\nMINUTE: Similar to “HOUR”, there are values set to 99.\nEVENTNUM, VNUMBER1, AOI1, SOE: These variables have a significant number of high values that could be considered outliers. However, without more context on what these numbers represent, it’s challenging to definitively label them as outliers.\n\nTo properly handle the potential outliers, we would need additional context on the data and the variables, especially for the ones with coded values (EVENTNUM, VNUMBER1, AOI1, SOE)."
  },
  {
    "objectID": "Data Exploration.html#report-and-discuss-your-methods-and-findings",
    "href": "Data Exploration.html#report-and-discuss-your-methods-and-findings",
    "title": "Explore the Data",
    "section": "",
    "text": "The dataset contains information about various incidents, with a total of 112,725 entries. There are 13 columns, consisting of both numerical and categorical variables.\n\n\n\n\n\n\nSTATE_x: Represents the state codes, ranging from 1 to 56.\nST_CASE: A unique case number assigned to each incident.\nDAY: Day of the incident, ranging from 1 to 31.\nHOUR: Hour of the day when the incident occurred, ranging from 0 to 99 (with 99 representing unknown values).\nMINUTE: Minute of the hour when the incident occurred, ranging from 0 to 99 (with 99 representing unknown values).\nEVENTNUM, VNUMBER1, AOI1, SOE: Coded variables representing various aspects of the incidents.\n\n\n\n\n\nSTATENAME_x: The name of the state where the incident occurred.\nDAY_WEEKNAME: The day of the week when the incident occurred.\nAOI1NAME: Descriptions related to the area of impact.\nSOENAME: Descriptions related to the sequence of events.\n\n\n\n\n\n\n\n\nSTATENAME_x: California and Texas have the highest number of incidents.\nDAY_WEEKNAME: Incidents are fairly evenly distributed across days of the week, with a slight increase on Saturdays and Sundays.\nAOI1NAME: “Non-Harmful Event” and “12 Clock Point” are the most common areas of impact\nSOENAME: “Motor Vehicle In-Transport” is the most common sequence of events.\n\n\n\n\n\nA strong positive correlation exists between STATE_x and ST_CASE, as case numbers are likely assigned sequentially within each state. HOUR and MINUTE have a positive correlation, suggesting a moderate relationship. EVENTNUM and VNUMBER1 also show a strong positive correlation. AOI1 and SOE have a moderate to strong positive correlation.\n\n\n\nHypotheses were generated related to time of day and incidents, weekend driving behavior, state-wise distribution of incidents, impact areas, and sequence of events.\n\n\n\nBy State:\nCalifornia and Texas have the highest number of incidents. Alaska, District of Columbia, and Rhode Island have the lowest.\nBy Time of Day:\nThe evening has the highest number of incidents, followed by the afternoon and night. The morning has the lowest number of incidents.\n\n\n\nPotential outliers were identified in the variables HOUR, MINUTE, EVENTNUM, VNUMBER1, AOI1, and SOE. The values 99 in HOUR and MINUTE are likely placeholders for unknown values."
  },
  {
    "objectID": "Data Exploration.html#tools-and-software",
    "href": "Data Exploration.html#tools-and-software",
    "title": "Explore the Data",
    "section": "",
    "text": "The analysis was performed using Python, leveraging libraries such as:\nPandas: For data manipulation and analysis. Matplotlib and Seaborn: For data visualization. NumPy: For numerical computations."
  },
  {
    "objectID": "DataMain.html",
    "href": "DataMain.html",
    "title": "Everything About Data",
    "section": "",
    "text": "Data\nData is the foundation of every data analysis, with more data, the more information we will get. On those sub-tab, you will find different steps of data analysis. It includes how I collected the data, how to clean those data, and in what ways I can explore them and elaborate based on those data."
  },
  {
    "objectID": "Data Cleaning Python.html#grouping-by-time-of-the-day",
    "href": "Data Cleaning Python.html#grouping-by-time-of-the-day",
    "title": "Grouping by State",
    "section": "Grouping by Time of the Day",
    "text": "Grouping by Time of the Day\n\n# Convert HOUR back to numeric, treating \"Unknown\" as a missing value\ndf['HOUR'] = pd.to_numeric(df['HOUR'], errors='coerce')\n\n# Define a function to categorize the time of day\ndef categorize_time_of_day(hour):\n    if pd.isna(hour):\n        return \"Unknown\"\n    elif 6 &lt;= hour &lt; 12:\n        return \"Morning\"\n    elif 12 &lt;= hour &lt; 18:\n        return \"Afternoon\"\n    elif 18 &lt;= hour &lt; 24:\n        return \"Evening\"\n    else:\n        return \"Night\"\n\n# Apply the function to create a new variable \"TIME_OF_DAY\"\ndf['TIME_OF_DAY'] = df['HOUR'].apply(categorize_time_of_day)\n\n# Group the data by \"TIME_OF_DAY\" and calculate the total number of entries for each time segment\ntime_of_day_group = df.groupby('TIME_OF_DAY').size().sort_index()\n\ntime_of_day_group\n\n# Set the size of the plot\nplt.figure(figsize=(10, 6))\n\n# Create a bar plot for the number of entries by time of day\nax = sns.barplot(x=time_of_day_group.index, y=time_of_day_group.values, palette=\"husl\")\n\n# Set the title and labels\nax.set_title('Number of Entries by Time of Day', fontsize=15)\nax.set_xlabel('Time of Day', fontsize=12)\nax.set_ylabel('Number of Entries', fontsize=12)\n\n# Show the plot\nplt.show()\n\n/var/folders/h3/qs6jt3s124g0xq78192txdnr0000gn/T/ipykernel_7091/1830726816.py:29: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  ax = sns.barplot(x=time_of_day_group.index, y=time_of_day_group.values, palette=\"husl\")\n\n\n\n\n\nidentify outliers\n\n# Set the size of the plots\nplt.figure(figsize=(15, 10))\n\n# Create box plots for the numerical variables\nfor i, column in enumerate(numerical_vars.columns, 1):\n    plt.subplot(3, 3, i)\n    sns.boxplot(x=df[column])\n    plt.title(column)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nEVENTNUM, VNUMBER1, AOI1, SOE: These variables have a significant number of high values that could be considered outliers. However, without more context on what these numbers represent, it’s challenging to definitively label them as outliers. To properly handle the potential outliers, we would need additional context on the data and the variables, especially for the ones with coded values (EVENTNUM, VNUMBER1, AOI1, SOE)."
  },
  {
    "objectID": "ts.html",
    "href": "ts.html",
    "title": "Grouping by State",
    "section": "",
    "text": "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n\naccident = pd.read_csv('Data/FARS2021NationalCSV/accident.csv', encoding='ISO-8859-1')\nevent = pd.read_csv('Data/FARS2021NationalCSV/cevent.csv', encoding='ISO-8859-1')\naccident.columns = accident.columns.str.strip()\nevent.columns = event.columns.str.strip()\naccident_columns_to_drop = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n                   36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n                   64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n\n# Drop the specified columns by index\naccident = accident.drop(accident.columns[accident_columns_to_drop], axis=1)\n\nevent_columns_to_drop = [9, 10, 11, 12]\nevent = event.drop(event.columns[event_columns_to_drop], axis = 1)\ndf = pd.merge(accident, event, on='ST_CASE', how='inner')\ndf\n\n\n\n\n\n\n\n\nSTATE_x\nSTATENAME_x\nST_CASE\nDAYNAME\nDAY_WEEKNAME\nHOUR\nMINUTE\nSTATE_y\nSTATENAME_y\nEVENTNUM\nVNUMBER1\nAOI1\nAOI1NAME\nSOE\nSOENAME\n\n\n\n\n0\n1\nAlabama\n10001\n12\nFriday\n22\n10\n1\nAlabama\n1\n1\n12\n12 Clock Point\n12\nMotor Vehicle In-Transport\n\n\n1\n1\nAlabama\n10002\n11\nThursday\n18\n0\n1\nAlabama\n1\n1\n55\nNon-Harmful Event\n64\nRan Off Roadway - Left\n\n\n2\n1\nAlabama\n10002\n11\nThursday\n18\n0\n1\nAlabama\n2\n1\n11\n11 Clock Point\n25\nConcrete Traffic Barrier\n\n\n3\n1\nAlabama\n10002\n11\nThursday\n18\n0\n1\nAlabama\n3\n1\n55\nNon-Harmful Event\n69\nRe-entering Roadway\n\n\n4\n1\nAlabama\n10002\n11\nThursday\n18\n0\n1\nAlabama\n4\n1\n55\nNon-Harmful Event\n63\nRan Off Roadway - Right\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n112720\n56\nWyoming\n560102\n15\nWednesday\n10\n34\n56\nWyoming\n1\n1\n55\nNon-Harmful Event\n63\nRan Off Roadway - Right\n\n\n112721\n56\nWyoming\n560102\n15\nWednesday\n10\n34\n56\nWyoming\n2\n1\n0\nNon-Collision\n1\nRollover/Overturn\n\n\n112722\n56\nWyoming\n560103\n19\nSunday\n17\n9\n56\nWyoming\n1\n1\n12\n12 Clock Point\n8\nPedestrian\n\n\n112723\n56\nWyoming\n560104\n20\nMonday\n6\n30\n56\nWyoming\n1\n1\n55\nNon-Harmful Event\n68\nCross Centerline\n\n\n112724\n56\nWyoming\n560104\n20\nMonday\n6\n30\n56\nWyoming\n2\n1\n12\n12 Clock Point\n12\nMotor Vehicle In-Transport\n\n\n\n\n112725 rows × 15 columns\nprint(df.shape)\n\n(112725, 15)\ndf = df.drop(columns=['STATE_y', 'STATENAME_y'])\nnumerical_vars = df.select_dtypes(include=[np.number])\nnumerical_summary = numerical_vars.describe()\n\n# Calculate variance for numerical variables (since it's not included in the describe method by default)\nvariance = numerical_vars.var()\n\n# Add variance to the summary statistics\nnumerical_summary.loc['variance'] = variance\n\nnumerical_summary\n\n\n\n\n\n\n\n\nSTATE_x\nST_CASE\nDAYNAME\nHOUR\nMINUTE\nEVENTNUM\nVNUMBER1\nAOI1\nSOE\n\n\n\n\ncount\n112725.000000\n1.127250e+05\n112725.000000\n112725.000000\n112725.000000\n112725.000000\n112725.000000\n112725.000000\n112725.000000\n\n\nmean\n27.475697\n2.756416e+05\n15.631076\n13.311040\n29.082990\n2.706480\n1.277764\n34.825301\n35.383633\n\n\nstd\n16.452688\n1.644243e+05\n8.871515\n10.491582\n18.481930\n3.216187\n2.629577\n30.664740\n25.523239\n\n\nmin\n1.000000\n1.000100e+04\n1.000000\n0.000000\n0.000000\n1.000000\n1.000000\n0.000000\n1.000000\n\n\n25%\n12.000000\n1.222640e+05\n8.000000\n7.000000\n14.000000\n1.000000\n1.000000\n12.000000\n12.000000\n\n\n50%\n27.000000\n2.704430e+05\n16.000000\n14.000000\n30.000000\n2.000000\n1.000000\n12.000000\n34.000000\n\n\n75%\n42.000000\n4.207750e+05\n23.000000\n19.000000\n44.000000\n3.000000\n1.000000\n55.000000\n63.000000\n\n\nmax\n56.000000\n5.601040e+05\n31.000000\n99.000000\n99.000000\n134.000000\n130.000000\n99.000000\n99.000000\n\n\nvariance\n270.690950\n2.703535e+10\n78.703777\n110.073297\n341.581745\n10.343860\n6.914676\n940.326272\n651.435726\nsns.set_style(\"whitegrid\")\n\n# Function to create bar plots for categorical variables\ndef plot_categorical_distribution(data, column_name, plot_size=(10, 6), rotation_angle=90):\n    plt.figure(figsize=plot_size)\n    ax = sns.countplot(data=data, y=column_name, order=data[column_name].value_counts().index,  palette=\"husl\")\n    ax.set_title(f'Crash Distribution Summary of {column_name}', fontsize=15)\n    ax.set_ylabel(column_name, fontsize=12)\n    ax.set_xlabel('Count', fontsize=12)\n    plt.xticks(rotation=rotation_angle)\n    plt.show()\n\n# Plot the distribution of STATENAME_x\nplot_categorical_distribution(df, 'STATENAME_x')\n\n/var/folders/h3/qs6jt3s124g0xq78192txdnr0000gn/T/ipykernel_5884/397954953.py:6: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  ax = sns.countplot(data=data, y=column_name, order=data[column_name].value_counts().index,  palette=\"husl\")\nplot_categorical_distribution(df, 'DAY_WEEKNAME', rotation_angle=0)\n\n/var/folders/h3/qs6jt3s124g0xq78192txdnr0000gn/T/ipykernel_5884/397954953.py:6: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  ax = sns.countplot(data=data, y=column_name, order=data[column_name].value_counts().index,  palette=\"husl\")\n# Plot the distribution of AOI1NAME with a rainbow color palette\nplot_categorical_distribution(df, 'AOI1NAME', plot_size=(10, 8))\n\n/var/folders/h3/qs6jt3s124g0xq78192txdnr0000gn/T/ipykernel_5884/397954953.py:6: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n\n  ax = sns.countplot(data=data, y=column_name, order=data[column_name].value_counts().index,  palette=\"husl\")\n# Calculate the correlation matrix for the numerical variables Step 4\ncorrelation_matrix = numerical_vars.corr()\n\ncorrelation_matrix\n\n# Set the size of the plot\nplt.figure(figsize=(10, 8))\n\n# Create a heatmap to visualize the correlation matrix\nax = sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n\n# Set the title and show the plot\nax.set_title('Correlation Matrix', fontsize=15)\nplt.show()\n\n\n\n\n\n\n\n\nSTATE_x\nST_CASE\nDAYNAME\nHOUR\nMINUTE\nEVENTNUM\nVNUMBER1\nAOI1\nSOE\n\n\n\n\nSTATE_x\n1.000000\n0.999983\n0.000383\n-0.002756\n0.004662\n0.027076\n0.036292\n-0.026817\n0.030156\n\n\nST_CASE\n0.999983\n1.000000\n0.000646\n-0.002934\n0.004684\n0.027070\n0.036291\n-0.026784\n0.029895\n\n\nDAYNAME\n0.000383\n0.000646\n1.000000\n0.004247\n0.001477\n-0.007234\n-0.016260\n-0.001981\n0.003662\n\n\nHOUR\n-0.002756\n-0.002934\n0.004247\n1.000000\n0.264396\n-0.029973\n-0.022275\n0.007379\n-0.005299\n\n\nMINUTE\n0.004662\n0.004684\n0.001477\n0.264396\n1.000000\n-0.041524\n-0.046012\n0.009566\n0.000916\n\n\nEVENTNUM\n0.027076\n0.027070\n-0.007234\n-0.029973\n-0.041524\n1.000000\n0.822694\n0.016616\n0.001920\n\n\nVNUMBER1\n0.036292\n0.036291\n-0.016260\n-0.022275\n-0.046012\n0.822694\n1.000000\n-0.014455\n0.048013\n\n\nAOI1\n-0.026817\n-0.026784\n-0.001981\n0.007379\n0.009566\n0.016616\n-0.014455\n1.000000\n0.563003\n\n\nSOE\n0.030156\n0.029895\n0.003662\n-0.005299\n0.000916\n0.001920\n0.048013\n0.563003\n1.000000\n# Set the size of the plot\nplt.figure(figsize=(10, 8))\n\n# Create a heatmap to visualize the correlation matrix\nax = sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n\n# Set the title and show the plot\nax.set_title('Correlation Matrix', fontsize=15)\nplt.show()\n# Convert HOUR from numeric to categorical to better handle the 99 (unknown) values\ndf['HOUR'] = df['HOUR'].astype(str).replace('99', 'Unknown')\n\n# Create a pivot table to count the number of entries for each combination of DAY_WEEKNAME and HOUR\nhour_weekday_pivot = pd.pivot_table(df, index='DAY_WEEKNAME', columns='HOUR', aggfunc='size', fill_value=0)\n\n# Order the days of the week\ndays_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\nhour_weekday_pivot = hour_weekday_pivot.reindex(days_order)\n\n# Create the heatmap\nplt.figure(figsize=(15, 7))\nax = sns.heatmap(hour_weekday_pivot, cmap=\"YlGnBu\", linewidths=.5)\n\n# Set the title and labels\nax.set_title('Number of Entries by Day of the Week and Hour of the Day', fontsize=15)\nax.set_xlabel('Hour of the Day', fontsize=12)\nax.set_ylabel('Day of the Week', fontsize=12)\n\nplt.show()\nHypothesis Generation Based on the exploratory data analysis we’ve conducted so far, here are some potential hypotheses and questions:\nTime of Day and Incidents:\nHypothesis: There are more incidents in the afternoon and evening compared to other times of the day. Potential Analysis: Investigate if certain types of incidents are more likely to occur during these times. Weekend Driving Behavior:\nHypothesis: Driving behavior during the weekends, especially late at night and in the early morning hours, leads to more incidents. Potential Analysis: Examine the types of incidents that occur during these times and if they are different from weekday incidents. State-wise Distribution:\nQuestion: Why do some states have significantly more incidents recorded in the dataset? Is it due to population, traffic volume, or data collection methods? Potential Analysis: Normalize the data by population or traffic volume to better understand the state-wise distribution. Impact Areas:\nHypothesis: Certain areas of impact, such as the “Non-Harmful Event” and “12 Clock Point”, are more common. Potential Analysis: Investigate the circumstances that lead to these common impact areas. Sequence of Events:\nHypothesis: The “Motor Vehicle In-Transport” event is the most common sequence of events leading to incidents. Potential Analysis: Explore what specific situations or factors contribute to this sequence of events.\nCalifornia and Texas have the highest number of entries, with 11,952 and 11,787 incidents respectively. States like Alaska, District of Columbia, and Rhode Island have the lowest number of entries, all below 150 incidents.\n# Group the data by state and calculate the total number of entries for each state\nstate_group = df.groupby('STATENAME_x').size().sort_values(ascending=False)\n\nstate_group\n\n# Set the size of the plot\nplt.figure(figsize=(12, 8))\n\n# Create a bar plot for the number of entries by state\nax = sns.barplot(x=state_group.index, y=state_group.values, palette=\"husl\")\n\n# Set the title and labels\nax.set_title('Number of Entries by State', fontsize=15)\nax.set_xlabel('State', fontsize=12)\nax.set_ylabel('Number of Entries', fontsize=12)\nplt.xticks(rotation=90)\n\n# Show the plot\nplt.show()\n\n\n/var/folders/h3/qs6jt3s124g0xq78192txdnr0000gn/T/ipykernel_5884/3716315958.py:10: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  ax = sns.barplot(x=state_group.index, y=state_group.values, palette=\"husl\")"
  },
  {
    "objectID": "ts.html#grouping-by-time-of-the-day",
    "href": "ts.html#grouping-by-time-of-the-day",
    "title": "Grouping by State",
    "section": "Grouping by Time of the Day",
    "text": "Grouping by Time of the Day\n\n# Convert HOUR back to numeric, treating \"Unknown\" as a missing value\ndf['HOUR'] = pd.to_numeric(df['HOUR'], errors='coerce')\n\n# Define a function to categorize the time of day\ndef categorize_time_of_day(hour):\n    if pd.isna(hour):\n        return \"Unknown\"\n    elif 6 &lt;= hour &lt; 12:\n        return \"Morning\"\n    elif 12 &lt;= hour &lt; 18:\n        return \"Afternoon\"\n    elif 18 &lt;= hour &lt; 24:\n        return \"Evening\"\n    else:\n        return \"Night\"\n\n# Apply the function to create a new variable \"TIME_OF_DAY\"\ndf['TIME_OF_DAY'] = df['HOUR'].apply(categorize_time_of_day)\n\n# Group the data by \"TIME_OF_DAY\" and calculate the total number of entries for each time segment\ntime_of_day_group = df.groupby('TIME_OF_DAY').size().sort_index()\n\ntime_of_day_group\n\n# Set the size of the plot\nplt.figure(figsize=(10, 6))\n\n# Create a bar plot for the number of entries by time of day\nax = sns.barplot(x=time_of_day_group.index, y=time_of_day_group.values, palette=\"husl\")\n\n# Set the title and labels\nax.set_title('Number of Entries by Time of Day', fontsize=15)\nax.set_xlabel('Time of Day', fontsize=12)\nax.set_ylabel('Number of Entries', fontsize=12)\n\n# Show the plot\nplt.show()\n\n\n/var/folders/h3/qs6jt3s124g0xq78192txdnr0000gn/T/ipykernel_5884/3951407133.py:29: FutureWarning: \n\nPassing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n\n  ax = sns.barplot(x=time_of_day_group.index, y=time_of_day_group.values, palette=\"husl\")\n\n\n\n\n\nStep 7\n\n# Set the size of the plots\nplt.figure(figsize=(15, 10))\n\n# Create box plots for the numerical variables\nfor i, column in enumerate(numerical_vars.columns, 1):\n    plt.subplot(3, 3, i)\n    sns.boxplot(x=df[column])\n    plt.title(column)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\nEVENTNUM, VNUMBER1, AOI1, SOE: These variables have a significant number of high values that could be considered outliers. However, without more context on what these numbers represent, it’s challenging to definitively label them as outliers. To properly handle the potential outliers, we would need additional context on the data and the variables, especially for the ones with coded values (EVENTNUM, VNUMBER1, AOI1, SOE)."
  }
]